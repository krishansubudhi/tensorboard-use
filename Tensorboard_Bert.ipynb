{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Tensorboard pytorch tutorial](https://krishansubudhi.github.io/deeplearning/2020/03/24/tensorboard-pytorch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clear everything first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for existing tensorboard processes\n",
      "cleaning tensorboard temp dir\n"
     ]
    }
   ],
   "source": [
    "! powershell \"echo 'checking for existing tensorboard processes'\"\n",
    "! powershell \"ps | Where-Object {$_.ProcessName -eq 'tensorboard'}\"\n",
    "\n",
    "! powershell \"ps | Where-Object {$_.ProcessName -eq 'tensorboard'}| %{kill $_}\"\n",
    "\n",
    "! powershell \"echo 'cleaning tensorboard temp dir'\"\n",
    "! powershell \"rm -Force -Recurse $env:TEMP\\.tensorboard-info\\*\" \n",
    "\n",
    "! powershell \"ps | Where-Object {$_.ProcessName -eq 'tensorboard'}\"\n",
    "! powershell \"rm -Force -Recurse runs\\*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Summary writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter('runs/tensorboard_bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load bert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers, torch\n",
    "from transformers import BertForPreTraining, BertTokenizer\n",
    "model = BertForPreTraining.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text = \"I am using tensorboard in pytorch. I am trying tensorboard to visualize BERT model.\"\n",
    "def get_tensors(text):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens.insert(0, tokenizer.cls_token)\n",
    "    tokens.append(tokenizer.sep_token)\n",
    "\n",
    "    correct_tensors = torch.LongTensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)\n",
    "\n",
    "    import numpy as np\n",
    "    # Masking 20% except first and last\n",
    "    for _ in range(len(tokens)//5):\n",
    "        i = np.random.randint(1, len(tokens)-1)\n",
    "        tokens[i] = tokenizer.mask_token\n",
    "\n",
    "\n",
    "    tensors = torch.LongTensor(tokenizer.convert_tokens_to_ids(tokens)).unsqueeze(0)\n",
    "    #print(tokens)\n",
    "    return  tokens, tensors, correct_tensors\n",
    "#get_tensors(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding model graph and embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.add_graph(model, torch.ones(1,128, dtype = torch.long))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding scalars and histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_grads(step,model):\n",
    "    print('Logging grads for ',step)\n",
    "    for name,param in model.named_parameters():\n",
    "        #print(name, param.grad.view(-1))\n",
    "        if ('bert.encoder.layer' in name and 'bert.encoder.layer.11' not in name):\n",
    "            continue\n",
    "        flat_params =  param.view(-1).data.numpy()\n",
    "        writer.add_histogram('weight/'+name, flat_params, step)\n",
    "        if param.grad is not None:\n",
    "            flat_params =  param.grad.view(-1).numpy()\n",
    "            writer.add_histogram('grads/'+name, flat_params, step)\n",
    "        \n",
    "#log_grads(0,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import adam\n",
    "optimizer = adam.Adam( model.parameters(),0.1)\n",
    "def run_step(step, model, tensors, correct_tensors, nsp_labels):\n",
    "    \n",
    "    #forward\n",
    "    loss,prediction_scores, nsp_score =  model.forward(tensors, masked_lm_labels = correct_tensors, next_sentence_label =nsp_labels )\n",
    "    \n",
    "    #scalars\n",
    "    preds = torch.argmax(prediction_scores, dim = -1)\n",
    "    acc = torch.sum(correct_tensors[:, 1:-1]==preds[:,1:-1]).item()/correct_tensors.size()[-1]\n",
    "    writer.add_scalar('Loss', loss.item(), step)\n",
    "    writer.add_scalar('Accuracy', acc, step)\n",
    "    \n",
    "    \n",
    "    #backwars\n",
    "    loss.backward()\n",
    "    log_grads(step, model)\n",
    "    \n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "I am using tensorboard in pytorch. I am trying tensorboard to visualize BERT model.\n",
      "Logging grads for  0\n",
      "['[CLS]', 'i', 'am', 'using', 'tensor', '##board', 'in', 'p', '##yt', '##or', '##ch', '.', 'i', 'am', '[MASK]', '[MASK]', '##board', 'to', 'visual', '##ize', '[MASK]', '[MASK]', '.', '[SEP]'] \n",
      "\n",
      "['.', 'i', 'am', 'using', 'tensor', '##board', 'in', 'p', '##yt', '##or', '##ch', '.', 'i', 'am', 'using', 'tensor', '##board', 'to', 'visual', '##ize', 'the', 'objects', '.', '.']\n",
      "\n",
      "This is not scaling.\n",
      "Logging grads for  1\n",
      "['[CLS]', 'this', '[MASK]', 'not', 'scaling', '.', '[SEP]'] \n",
      "\n",
      "['##ize', '##ize', '##ize', '##ize', '##ize', '##ize', '##ize']\n",
      "\n",
      "Working from home these days because of lockdown.\n",
      "Logging grads for  2\n",
      "['[CLS]', 'working', '[MASK]', 'home', '[MASK]', 'days', 'because', 'of', 'lock', '##down', '.', '[SEP]'] \n",
      "\n",
      "['mac', 'mac', 'mac', 'mac', 'mac', 'mac', 'mac', 'mac', 'mac', 'mac', 'mac', 'mac']\n",
      "\n",
      "Hidden cup 3 for age of empires is awesome\n",
      "Logging grads for  3\n",
      "['[CLS]', 'hidden', 'cup', '3', 'for', 'age', '[MASK]', 'empires', 'is', '[MASK]', '[SEP]'] \n",
      "\n",
      "['these', 'these', 'these', 'these', 'these', 'these', 'these', 'these', 'these', 'these', 'these']\n",
      "\n",
      "epoch 1\n",
      "I am using tensorboard in pytorch. I am trying tensorboard to visualize BERT model.\n",
      "Logging grads for  4\n",
      "['[CLS]', 'i', 'am', 'using', 'tensor', '##board', '[MASK]', 'p', '##yt', '##or', '##ch', '[MASK]', 'i', 'am', '[MASK]', 'tensor', '##board', '[MASK]', 'visual', '##ize', 'bert', 'model', '.', '[SEP]'] \n",
      "\n",
      "['of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of', 'of']\n",
      "\n",
      "This is not scaling.\n",
      "Logging grads for  5\n",
      "['[CLS]', 'this', 'is', '[MASK]', 'scaling', '.', '[SEP]'] \n",
      "\n",
      "['[CLS]', '[CLS]', '[CLS]', '[CLS]', '[CLS]', '[CLS]', '[CLS]']\n",
      "\n",
      "Working from home these days because of lockdown.\n",
      "Logging grads for  6\n",
      "['[CLS]', 'working', 'from', 'home', 'these', '[MASK]', 'because', 'of', 'lock', '##down', '[MASK]', '[SEP]'] \n",
      "\n",
      "['[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]', '[SEP]']\n",
      "\n",
      "Hidden cup 3 for age of empires is awesome\n",
      "Logging grads for  7\n",
      "['[CLS]', 'hidden', 'cup', '3', '[MASK]', '[MASK]', 'of', 'empires', 'is', 'awesome', '[SEP]'] \n",
      "\n",
      "['.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "texts = [\"I am using tensorboard in pytorch. I am trying tensorboard to visualize BERT model.\",\n",
    "       \"This is not scaling.\",\n",
    "       \"Working from home these days because of lockdown.\",\n",
    "       \"Hidden cup 3 for age of empires is awesome\"]\n",
    "for epoch in range(2):\n",
    "    print('epoch',epoch)\n",
    "    for i,text in enumerate(texts):\n",
    "        print (text)\n",
    "        tokens, tensors, correct_tensors = get_tensors(text)\n",
    "        preds =  run_step(epoch*len(texts) + i, model, tensors, correct_tensors, nsp_labels = torch.ones(1,1,dtype = torch.long))\n",
    "        predicted_tokens = tokenizer.convert_ids_to_tokens(preds.squeeze().numpy())\n",
    "        print(tokens,'\\n')\n",
    "        print(predicted_tokens)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()\n",
    "\n",
    "writer.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pwd' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "    Directory: C:\\Users\\krkusuk\\projects\\tensorboard\\runs\n",
      "\n",
      "\n",
      "Mode                LastWriteTime         Length Name                          \n",
      "----                -------------         ------ ----                          \n",
      "d-----        3/25/2020  11:58 AM                tensorboard_bert              \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "! pwd\n",
    "! powershell \"ls runs\"\n",
    "# Run in a new anaconda powershell. Change path for linux\n",
    "# ! tensorboard --logdir=\"C:\\Users\\krkusuk\\projects\\tensorboard\\runs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
