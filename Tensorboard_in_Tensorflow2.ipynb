{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorboard\n",
    "\n",
    "# https://www.tensorflow.org/install/pip\n",
    "# !pip install tensorflow-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.tensorflow.org/tensorboard/get_started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logs\\gradient_tape\\20200323-143745\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "log_dir = os.path.join('logs','gradient_tape', datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
    "print(log_dir)\n",
    "\n",
    "\n",
    "!powershell rm -Force -R logs\n",
    "\n",
    "\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "!powershell dir $log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train,y_train),(x_test,y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "\n",
    "def create_model():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape = (28,28)),\n",
    "        tf.keras.layers.Dense(512, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(10,activation='softmax')\n",
    "    ])\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "\n",
    "train_dataset = train_dataset.shuffle(60000).batch(64)\n",
    "test_dataset = test_dataset.batch(64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# Define our metrics\n",
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')\n",
    "\n",
    "def train_step(model, optimizer, x_train, y_train):\n",
    "  with tf.GradientTape() as tape:\n",
    "    predictions = model(x_train, training=True)\n",
    "    loss = loss_object(y_train, predictions)\n",
    "  grads = tape.gradient(loss, model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "  train_loss(loss)\n",
    "  train_accuracy(y_train, predictions)\n",
    "    \n",
    "def test_step(model, x_test, y_test):\n",
    "  predictions = model(x_test)\n",
    "  loss = loss_object(y_test, predictions)\n",
    "\n",
    "  test_loss(loss)\n",
    "  test_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - Layer flatten_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.24486394226551056, Accuracy: 92.85166931152344, Test Loss: 0.12080260366201401, Test Accuracy: 96.3800048828125\n",
      "Epoch 2, Loss: 0.10387572646141052, Accuracy: 96.89166259765625, Test Loss: 0.08313678950071335, Test Accuracy: 97.3699951171875\n",
      "Epoch 3, Loss: 0.0713011771440506, Accuracy: 97.8516616821289, Test Loss: 0.06803753226995468, Test Accuracy: 97.83999633789062\n",
      "Epoch 4, Loss: 0.0551285520195961, Accuracy: 98.30833435058594, Test Loss: 0.06910602003335953, Test Accuracy: 97.93999481201172\n",
      "Epoch 5, Loss: 0.04369373992085457, Accuracy: 98.60333251953125, Test Loss: 0.060588810592889786, Test Accuracy: 98.13999938964844\n"
     ]
    }
   ],
   "source": [
    "train_log_dir = os.path.join(log_dir,'train')\n",
    "test_log_dir = os.path.join(log_dir,'test')\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)\n",
    "\n",
    "\n",
    "model = create_model() # reset our model\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "  for (x_train, y_train) in train_dataset:\n",
    "    train_step(model, optimizer, x_train, y_train)\n",
    "  with train_summary_writer.as_default():\n",
    "    tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "    tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "  for (x_test, y_test) in test_dataset:\n",
    "    test_step(model, x_test, y_test)\n",
    "  with test_summary_writer.as_default():\n",
    "    tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "    tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "  \n",
    "  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "  print (template.format(epoch+1,\n",
    "                         train_loss.result(), \n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(), \n",
    "                         test_accuracy.result()*100))\n",
    "\n",
    "  # Reset metrics every epoch\n",
    "  train_loss.reset_states()\n",
    "  test_loss.reset_states()\n",
    "  train_accuracy.reset_states()\n",
    "  test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Issues and resolution\n",
    "Observed that once tensorflow goes into a bad state, it throws problem everytime after because \n",
    "\n",
    "1. It does not kill previous processes automatically\n",
    "2. It uses previous states while starting the dashboard\n",
    "\n",
    "Steps to mitigate the bad state:\n",
    "\n",
    "1. kill all running tensorboard processes.\n",
    "2. Clear previous tensorboard state.\n",
    "\n",
    "\n",
    "\n",
    "If it times out in jupyter, then go to http://localhost:6006/#scalars in the browser and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking for existing tensorboard processes\n",
      "\n",
      "Handles  NPM(K)    PM(K)      WS(K)     CPU(s)     Id  SI ProcessName          \n",
      "-------  ------    -----      -----     ------     --  -- -----------          \n",
      "     87       6      940       4056       0.02   1760   1 tensorboard          \n",
      "\n",
      "\n",
      "killing existing tensorboard processes\n",
      "cleaning tensorboard temp dir\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ERROR: Timed out waiting for TensorBoard to start. It may still be running as pid 20828."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "! powershell \"echo 'checking for existing tensorboard processes'\"\n",
    "! powershell \"ps | Where-Object {$_.ProcessName -eq 'tensorboard'}\"\n",
    "! powershell \"echo 'killing existing tensorboard processes'\"\n",
    "! powershell \"ps | Where-Object {$_.ProcessName -eq 'tensorboard'}| %{kill $_}\"\n",
    "\n",
    "! powershell \"echo 'cleaning tensorboard temp dir'\"\n",
    "! powershell \"rm $env:TEMP\\.tensorboard-info\\*\"\n",
    "\n",
    "! powershell \"ps | Where-Object {$_.ProcessName -eq 'tensorboard'}\"\n",
    "\n",
    "\n",
    "%tensorboard --logdir=\"logs\" --host localhost #quotes are important in windows\n",
    "# If it times out in jupyter, then go to http://localhost:6006/#scalars in the browser and check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References:\n",
    "\n",
    "1. No dashboard active error:\n",
    "\n",
    "https://stackoverflow.com/questions/47113472/tensorboard-error-no-dashboards-are-active-for-current-data-set\n",
    "\n",
    "\n",
    "2. [Windows] tensorboard - needs to be started from same drive as logdir \n",
    "\n",
    "https://github.com/tensorflow/tensorflow/issues/7856\n",
    "\n",
    "3. localhost refused to connect.\n",
    "\n",
    "https://github.com/tensorflow/tensorboard/issues/2481\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
